{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Multi-GPU Mirrored Strategy\n\n**MirroredStrategy**\n\ntf.distribute.MirroredStrategy supports synchronous distributed training on multiple GPUs on one machine. It creates one replica per GPU device. Each variable in the model is mirrored across all the replicas. Together, these variables form a single conceptual variable called MirroredVariable. These variables are kept in sync with each other by applying identical updates.\n\nEfficient all-reduce algorithms are used to communicate the variable updates across the devices. All-reduce aggregates tensors across all the devices by adding them up, and makes them available on each device. It‚Äôs a fused algorithm that is very efficient and can reduce the overhead of synchronization significantly. There are many all-reduce algorithms and implementations available, depending on the type of communication available between devices. By default, it uses the NVIDIA Collective Communication Library (NCCL) as the all-reduce implementation. You can choose from a few other options or write your own.","metadata":{}},{"cell_type":"markdown","source":"# Imports Libs ‚öíÔ∏è ‚öôÔ∏è","metadata":{}},{"cell_type":"code","source":"# Import Required Libs , TensorFlow ,and TensorFlow Datasets\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nimport os, time\nimport numpy as np\nfrom IPython.display import HTML,display\n\ntry:\n  # %tensorflow_version only exists .\n  %tensorflow_version 2.x\nexcept Exception:\n  pass\n\nimport tensorflow_datasets as tfds\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport matplotlib.pyplot as plt\n\ntfds.disable_progress_bar()\n\n\n","metadata":{"id":"TkUjfmKkflCd","execution":{"iopub.status.busy":"2023-05-11T11:07:14.051491Z","iopub.execute_input":"2023-05-11T11:07:14.051838Z","iopub.status.idle":"2023-05-11T11:07:30.347981Z","shell.execute_reply.started":"2023-05-11T11:07:14.051810Z","shell.execute_reply":"2023-05-11T11:07:30.346977Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Load Data ‚åõ","metadata":{}},{"cell_type":"markdown","source":"`TFDS` provides a collection of ready-to-use datasets for use with TensorFlow, and other Machine Learning frameworks.\n\nIt handles downloading and preparing the data deterministically and constructing a tf.data.Dataset (or np.array).\n\nWe are going to use the `fashion_mnist` dataset  which is only split into a `TRAINING` set. We have to use tfds.splits to split this training set into to a training_set, a validation_set, and a test_set. \n\nIn this example we are splitting:\n- Train data \n- Test data","metadata":{}},{"cell_type":"code","source":"# Load the Fashion-MNIST dataset\n(train_images, train_labels), (test_images, test_labels)= tf.keras.datasets.fashion_mnist.load_data()\n","metadata":{"id":"eQN-PtIGgFtH","execution":{"iopub.status.busy":"2023-05-11T11:07:30.350030Z","iopub.execute_input":"2023-05-11T11:07:30.350835Z","iopub.status.idle":"2023-05-11T11:07:31.237968Z","shell.execute_reply.started":"2023-05-11T11:07:30.350798Z","shell.execute_reply":"2023-05-11T11:07:31.236994Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n29515/29515 [==============================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n26421880/26421880 [==============================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n5148/5148 [==============================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n4422102/4422102 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Explore & visualize Data  üîç üìä üëÄ","metadata":{}},{"cell_type":"code","source":"# Get the number of examples in each set from the dataset info.\nprint('Total Number of Training Images: {}'.format(len(train_images)))\nprint('Total Number of Test Images: {} \\n'.format(len(test_images)))","metadata":{"execution":{"iopub.status.busy":"2023-05-11T11:07:33.470046Z","iopub.execute_input":"2023-05-11T11:07:33.470696Z","iopub.status.idle":"2023-05-11T11:07:33.475691Z","shell.execute_reply.started":"2023-05-11T11:07:33.470662Z","shell.execute_reply":"2023-05-11T11:07:33.474693Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Total Number of Training Images: 60000\nTotal Number of Test Images: 10000 \n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Get the class names from the dataset\nclass_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\nnum_classes = len(class_names)\n\nprint(class_names)\nprint('Total Number of Classes: {}'.format(num_classes))","metadata":{"execution":{"iopub.status.busy":"2023-05-11T11:07:33.662838Z","iopub.execute_input":"2023-05-11T11:07:33.663130Z","iopub.status.idle":"2023-05-11T11:07:33.669362Z","shell.execute_reply.started":"2023-05-11T11:07:33.663105Z","shell.execute_reply":"2023-05-11T11:07:33.668300Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\nTotal Number of Classes: 10\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Process Data  üëÄ üßê","metadata":{}},{"cell_type":"code","source":"train_images = train_images.astype('float32') / 255.0\ntest_images = test_images.astype('float32') / 255.0","metadata":{"execution":{"iopub.status.busy":"2023-05-11T11:07:35.595270Z","iopub.execute_input":"2023-05-11T11:07:35.595950Z","iopub.status.idle":"2023-05-11T11:07:35.681893Z","shell.execute_reply.started":"2023-05-11T11:07:35.595910Z","shell.execute_reply":"2023-05-11T11:07:35.680857Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Initialize Strategy üëÄ üßê","metadata":{}},{"cell_type":"markdown","source":"Now, you define `strategy` using the `MirroredStrategy()` class. Print to see the number of devices available.\n\n**Note:** \n- If you are running this in Kaggle, make sure you have selected your `Accelerator` to be `GPU T4*2` for it to detect it. \n- 2 device that is available.  \n","metadata":{}},{"cell_type":"markdown","source":"- **Muli GPU Mirrored Strategy**\n- **Running [[ GPU T4 *2  ]] Mode on Kaggle**\n- **Providing `2 GPU`**","metadata":{}},{"cell_type":"code","source":"\n# Define the strategy to use and print the number of devices found\nstrategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\nprint ('Number of devices: {}'.format(strategy.num_replicas_in_sync))","metadata":{"id":"eCsDqWnDgNHr","execution":{"iopub.status.busy":"2023-05-11T11:07:45.556029Z","iopub.execute_input":"2023-05-11T11:07:45.556426Z","iopub.status.idle":"2023-05-11T11:07:50.978641Z","shell.execute_reply.started":"2023-05-11T11:07:45.556396Z","shell.execute_reply":"2023-05-11T11:07:50.977676Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Number of devices: 2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**P.Süí°** Now, we create training and eval examples, define `batch size` and also define `BATCH_SIZE_PER_REPLICA` which is the distribution we are making for each available device. ‚åõ","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE_PER_REPLICA = 128\n# Use for Mirrored Strategy\nGLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n\n# Use for No Strategy , when we run on a singel machine\n# BATCH_SIZE = BATCH_SIZE_PER_REPLICA * 1\n\nprint ('BATCH_SIZE_PER_REPLICA',BATCH_SIZE_PER_REPLICA )\nprint ('GLOBAL_BATCH_SIZE on the machine (BATCH_SIZE_PER_REPLICA * No. of GPUs) =',GLOBAL_BATCH_SIZE )","metadata":{"execution":{"iopub.status.busy":"2023-05-11T11:07:52.658264Z","iopub.execute_input":"2023-05-11T11:07:52.658661Z","iopub.status.idle":"2023-05-11T11:07:52.664421Z","shell.execute_reply.started":"2023-05-11T11:07:52.658622Z","shell.execute_reply":"2023-05-11T11:07:52.663494Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"BATCH_SIZE_PER_REPLICA 128\nGLOBAL_BATCH_SIZE on the machine (BATCH_SIZE_PER_REPLICA * No. of GPUs) = 256\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(60000).batch(GLOBAL_BATCH_SIZE)\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-05-11T11:07:52.844730Z","iopub.execute_input":"2023-05-11T11:07:52.845045Z","iopub.status.idle":"2023-05-11T11:07:53.283595Z","shell.execute_reply.started":"2023-05-11T11:07:52.845019Z","shell.execute_reply":"2023-05-11T11:07:53.282664Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Bulid Model  ‚öôÔ∏èüèóÔ∏è ","metadata":{}},{"cell_type":"markdown","source":"- For model to follow the strategy, we need to define the model within the strategy's scope using `with strategy.scope():` \n\n- The important thing to notice and compare is the time taken for each `epoch` to complete.","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    model = tf.keras.Sequential([\n      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n      tf.keras.layers.MaxPooling2D(),\n      tf.keras.layers.Flatten(),\n      tf.keras.layers.Dense(64, activation='relu'),\n      tf.keras.layers.Dense(10)\n    ])\n    \n    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2023-05-11T11:07:56.231222Z","iopub.execute_input":"2023-05-11T11:07:56.231581Z","iopub.status.idle":"2023-05-11T11:07:56.439354Z","shell.execute_reply.started":"2023-05-11T11:07:56.231554Z","shell.execute_reply":"2023-05-11T11:07:56.438451Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Train Model üî• üå°Ô∏è\n\nLet the Magic Begin !üîÆ","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    EPOCHS = 10\n    start = time.time()\n    model.fit(train_dataset, epochs=EPOCHS)\n    end = time.time()","metadata":{"execution":{"iopub.status.busy":"2023-05-11T11:09:52.960641Z","iopub.execute_input":"2023-05-11T11:09:52.960998Z","iopub.status.idle":"2023-05-11T11:10:22.233335Z","shell.execute_reply.started":"2023-05-11T11:09:52.960968Z","shell.execute_reply":"2023-05-11T11:10:22.232361Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/10\n235/235 [==============================] - 2s 10ms/step - loss: 2.3025 - accuracy: 0.0603\nEpoch 2/10\n235/235 [==============================] - 2s 10ms/step - loss: 2.3025 - accuracy: 0.0603\nEpoch 3/10\n235/235 [==============================] - 2s 10ms/step - loss: 2.3025 - accuracy: 0.0603\nEpoch 4/10\n235/235 [==============================] - 3s 11ms/step - loss: 2.3025 - accuracy: 0.0603\nEpoch 5/10\n235/235 [==============================] - 3s 12ms/step - loss: 2.3025 - accuracy: 0.0603\nEpoch 6/10\n235/235 [==============================] - 2s 10ms/step - loss: 2.3025 - accuracy: 0.0603\nEpoch 7/10\n235/235 [==============================] - 2s 10ms/step - loss: 2.3025 - accuracy: 0.0603\nEpoch 8/10\n235/235 [==============================] - 3s 11ms/step - loss: 2.3025 - accuracy: 0.0603\nEpoch 9/10\n235/235 [==============================] - 2s 10ms/step - loss: 2.3025 - accuracy: 0.0603\nEpoch 10/10\n235/235 [==============================] - 2s 10ms/step - loss: 2.3025 - accuracy: 0.0603\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**P.S.üí°** The `time` library is being utilized to estimate the duration of the model training process. Specifically, the number of `epochs` is set to `10`, ","metadata":{}},{"cell_type":"code","source":"duration = round( end - start , 2) \ndisplay(HTML(f\"<h5><b >The duration required for the model to train using Multiple GPU Mirrored Strategy : </b> <b style='color:red'>{duration} Seconds üßê  ‚ú®. </b></h5>\"))","metadata":{"execution":{"iopub.status.busy":"2023-05-11T11:10:25.044766Z","iopub.execute_input":"2023-05-11T11:10:25.045637Z","iopub.status.idle":"2023-05-11T11:10:25.053278Z","shell.execute_reply.started":"2023-05-11T11:10:25.045585Z","shell.execute_reply":"2023-05-11T11:10:25.052225Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<h5><b >The duration required for the model to train using Multiple GPU Mirrored Strategy : </b> <b style='color:red'>29.27 Seconds üßê  ‚ú®. </b></h5>"},"metadata":{}}]}]}
