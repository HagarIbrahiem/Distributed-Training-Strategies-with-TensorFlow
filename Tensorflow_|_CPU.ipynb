{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HagarIbrahiem/Distributed-Training-Strategies-with-TensorFlow/blob/main/Tensorflow_%7C_CPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mirrored Strategy: Basic\n",
        "\n",
        "Train the model using [Mirrored Strategy -One GPU](https://www.tensorflow.org/api_docs/python/tf/distribute/MirroredStrategy)\n",
        "\n",
        "\n",
        " **MirroredStrategy**\n",
        "\n",
        "`tf.distribute.MirroredStrategy` supports synchronous distributed training on multiple GPUs on one machine. It creates one replica per GPU device. Each variable in the model is mirrored across all the replicas. Together, these variables form a single conceptual variable called `MirroredVariable`. These variables are kept in sync with each other by applying identical updates.\n",
        "\n",
        "Efficient all-reduce algorithms are used to communicate the variable updates across the devices. All-reduce aggregates tensors across all the devices by adding them up, and makes them available on each device. It‚Äôs a fused algorithm that is very efficient and can reduce the overhead of synchronization significantly. There are many all-reduce algorithms and implementations available, depending on the type of communication available between devices. By default, it uses the NVIDIA Collective Communication Library ([NCCL](https://developer.nvidia.com/nccl)) as the all-reduce implementation. You can choose from a few other options or write your own.\n",
        "\n"
      ],
      "metadata": {
        "id": "SsXV3wLxMQLI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports Libs ‚öíÔ∏è ‚öôÔ∏è"
      ],
      "metadata": {
        "id": "1gw66v4TMQLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Required Libs , TensorFlow ,and TensorFlow Datasets\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "import os, time\n",
        "import numpy as np\n",
        "from IPython.display import HTML,display\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists .\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TkUjfmKkflCd",
        "execution": {
          "iopub.status.busy": "2023-05-11T09:29:38.867506Z",
          "iopub.execute_input": "2023-05-11T09:29:38.868746Z",
          "iopub.status.idle": "2023-05-11T09:29:51.485505Z",
          "shell.execute_reply.started": "2023-05-11T09:29:38.868672Z",
          "shell.execute_reply": "2023-05-11T09:29:51.484155Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70245122-63ae-46c1-f71c-bb432655d62f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "BATCH_SIZE = 32\n",
        "BUFFER_SIZE = 10000"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-11T09:30:01.955808Z",
          "iopub.execute_input": "2023-05-11T09:30:01.956649Z",
          "iopub.status.idle": "2023-05-11T09:30:01.965010Z",
          "shell.execute_reply.started": "2023-05-11T09:30:01.956608Z",
          "shell.execute_reply": "2023-05-11T09:30:01.962351Z"
        },
        "trusted": true,
        "id": "_mwaE45BMQLV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data ‚åõ"
      ],
      "metadata": {
        "id": "_megQIhXMQLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`TFDS` provides a collection of ready-to-use datasets for use with TensorFlow, and other Machine Learning frameworks.\n",
        "\n",
        "It handles downloading and preparing the data deterministically and constructing a tf.data.Dataset (or np.array).\n",
        "\n",
        "We are going to use the `fashion_mnist` dataset  which is only split into a `TRAINING` set. We have to use tfds.splits to split this training set into to a training_set, and a test_set. \n"
      ],
      "metadata": {
        "id": "_zHDXMNKMQLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Fashion-MNIST dataset\n",
        "\n",
        "datasets, info = tfds.load(name='fashion_mnist', with_info=True, as_supervised=True, data_dir='./data')\n",
        "\n"
      ],
      "metadata": {
        "id": "eQN-PtIGgFtH",
        "execution": {
          "iopub.status.busy": "2023-05-11T09:30:04.037091Z",
          "iopub.execute_input": "2023-05-11T09:30:04.037574Z",
          "iopub.status.idle": "2023-05-11T09:30:37.687278Z",
          "shell.execute_reply.started": "2023-05-11T09:30:04.037537Z",
          "shell.execute_reply": "2023-05-11T09:30:37.686073Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c5e7922-e5de-4ba9-a1d9-92c0bbabd069"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 29.45 MiB (download: 29.45 MiB, generated: 36.42 MiB, total: 65.87 MiB) to ./data/fashion_mnist/3.0.1...\n",
            "Dataset fashion_mnist downloaded and prepared to ./data/fashion_mnist/3.0.1. Subsequent calls will reuse this data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist_train, fashion_mnist_test = datasets['train'], datasets['test']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-11T09:30:43.094767Z",
          "iopub.execute_input": "2023-05-11T09:30:43.095589Z",
          "iopub.status.idle": "2023-05-11T09:30:43.101241Z",
          "shell.execute_reply.started": "2023-05-11T09:30:43.095541Z",
          "shell.execute_reply": "2023-05-11T09:30:43.100273Z"
        },
        "trusted": true,
        "id": "TMFyKBgxMQLZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explore & visualize Data  üîç üìä üëÄ"
      ],
      "metadata": {
        "id": "YZFnsiV7MQLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of examples in each set from the dataset info.\n",
        "print('Total Number of Training Images: {}'.format(len(fashion_mnist_train)))\n",
        "print('Total Number of Test Images: {} \\n'.format(len(fashion_mnist_test)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-11T09:30:44.760677Z",
          "iopub.execute_input": "2023-05-11T09:30:44.761375Z",
          "iopub.status.idle": "2023-05-11T09:30:44.770091Z",
          "shell.execute_reply.started": "2023-05-11T09:30:44.761326Z",
          "shell.execute_reply": "2023-05-11T09:30:44.768945Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9y_w42IMQLb",
        "outputId": "816f6e91-9a21-4e0e-9ed5-a239ebd08914"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of Training Images: 60000\n",
            "Total Number of Test Images: 10000 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get the class names from the dataset\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "num_classes = len(class_names)\n",
        "\n",
        "print(class_names)\n",
        "print('Total Number of Classes: {}'.format(num_classes))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-11T09:30:45.750060Z",
          "iopub.execute_input": "2023-05-11T09:30:45.750458Z",
          "iopub.status.idle": "2023-05-11T09:30:45.758378Z",
          "shell.execute_reply.started": "2023-05-11T09:30:45.750425Z",
          "shell.execute_reply": "2023-05-11T09:30:45.756807Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhFdhh9CMQLc",
        "outputId": "40cd998d-fb54-4580-d730-c678054c5b28"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
            "Total Number of Classes: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process Data  üëÄ üßê"
      ],
      "metadata": {
        "id": "LNBXqheoMQLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for normalizing the image\n",
        "def scale(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image /= 255\n",
        "\n",
        "    return image, label"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-11T09:30:46.983355Z",
          "iopub.execute_input": "2023-05-11T09:30:46.983815Z",
          "iopub.status.idle": "2023-05-11T09:30:46.991077Z",
          "shell.execute_reply.started": "2023-05-11T09:30:46.983781Z",
          "shell.execute_reply": "2023-05-11T09:30:46.989830Z"
        },
        "trusted": true,
        "id": "-j1iXg0tMQLd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**P.Süí°** Next, you create your training and test datesets in the batch size you want by shuffling through your buffer size. ‚åõ"
      ],
      "metadata": {
        "id": "PaR-tBhLMQLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the train and eval data set\n",
        "train_dataset = fashion_mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "eval_dataset = fashion_mnist_test.map(scale).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-11T09:30:50.875526Z",
          "iopub.execute_input": "2023-05-11T09:30:50.877108Z",
          "iopub.status.idle": "2023-05-11T09:30:51.346725Z",
          "shell.execute_reply.started": "2023-05-11T09:30:50.877046Z",
          "shell.execute_reply": "2023-05-11T09:30:51.345254Z"
        },
        "trusted": true,
        "id": "eE8yR22PMQLf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bulid Model  ‚öôÔ∏èüèóÔ∏è "
      ],
      "metadata": {
        "id": "ig5sucpFMQLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10)\n",
        "  \n",
        "   ])"
      ],
      "metadata": {
        "id": "7rRzY5ojh51B",
        "execution": {
          "iopub.status.busy": "2023-05-11T09:39:18.123329Z",
          "iopub.execute_input": "2023-05-11T09:39:18.123966Z",
          "iopub.status.idle": "2023-05-11T09:39:18.221432Z",
          "shell.execute_reply.started": "2023-05-11T09:39:18.123916Z",
          "shell.execute_reply": "2023-05-11T09:39:18.220233Z"
        },
        "trusted": true
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# configure the optimizer, loss and metrics\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# display summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-11T09:39:27.022324Z",
          "iopub.execute_input": "2023-05-11T09:39:27.022775Z",
          "iopub.status.idle": "2023-05-11T09:39:27.066830Z",
          "shell.execute_reply.started": "2023-05-11T09:39:27.022739Z",
          "shell.execute_reply": "2023-05-11T09:39:27.065339Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOcdUheqMQLj",
        "outputId": "96ace104-e828-4348-85e9-358b485329f9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 5408)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                346176    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 347,146\n",
            "Trainable params: 347,146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**P.S.üí°**\n",
        "Due to the Total params: `23,571,397` consisting of `10,245` trainable params and `23,561,152` non-trainable params, running this large model on a typical `CPU` will require a considerable amount of time"
      ],
      "metadata": {
        "id": "LAbnSeZVMQLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model  üî• üå°Ô∏è \n",
        "\n",
        "Let the Magic Begin !üîÆ"
      ],
      "metadata": {
        "id": "iEBT0Nv5MQLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "start = time.time()\n",
        "model.fit(train_dataset, epochs=EPOCHS)\n",
        "end = time.time()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-11T09:39:39.898936Z",
          "iopub.execute_input": "2023-05-11T09:39:39.899383Z",
          "iopub.status.idle": "2023-05-11T09:39:39.904411Z",
          "shell.execute_reply.started": "2023-05-11T09:39:39.899349Z",
          "shell.execute_reply": "2023-05-11T09:39:39.903301Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNV_qbjEMQLk",
        "outputId": "cdcbb044-ac58-4f7e-b29a-e6dd620efab6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 2.3026 - accuracy: 0.2291\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 37s 20ms/step - loss: 2.3026 - accuracy: 0.2291\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 2.3026 - accuracy: 0.2291\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 2.3026 - accuracy: 0.2291\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 2.3026 - accuracy: 0.2291\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 2.3026 - accuracy: 0.2291\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 2.3026 - accuracy: 0.2291\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 2.3026 - accuracy: 0.2291\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 2.3026 - accuracy: 0.2291\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 2.3026 - accuracy: 0.2291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**P.S.üí°** The `time` library is being utilized to estimate the duration of the model training process. Specifically, the number of `epochs` is set to `10`, "
      ],
      "metadata": {
        "id": "8hfC73xlMQLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duration = round( end - start , 2) \n",
        "\n",
        "display(HTML(f\"<h5><b >The duration required for the model to train using CPU: </b> <b style='color:red'>{duration} Seconds üßê  ‚ú®. </b></h5>\"))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-11T09:39:47.936316Z",
          "iopub.execute_input": "2023-05-11T09:39:47.936774Z",
          "iopub.status.idle": "2023-05-11T09:39:47.942248Z",
          "shell.execute_reply.started": "2023-05-11T09:39:47.936738Z",
          "shell.execute_reply": "2023-05-11T09:39:47.940752Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "EsaNP1NeMQLl",
        "outputId": "936b3705-bc69-4db4-89bd-0f199a70ee24"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h5><b >The duration required for the model to train using CPU: </b> <b style='color:red'>441.03 Seconds üßê  ‚ú®. </b></h5>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qHI8WF9pWEeg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}